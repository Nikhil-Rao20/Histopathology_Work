\documentclass[11pt,a4paper]{article}
\usepackage[margin=1in]{geometry}
\usepackage{booktabs}
\usepackage{array}
\usepackage{xcolor}
\usepackage{multirow}

\definecolor{best}{RGB}{0,100,0}

\title{\textbf{CIPS-Net vs SAM: Nuclei Segmentation Evaluation}}
\date{January 2026}

\begin{document}

\maketitle

\section{Introduction}

We trained CIPS-Net (Compositional Instruction-conditioned Pathology Segmentation Network) on the PanNuke dataset using 3-fold cross-validation with three different configurations: (1) ViT-B/16 + DistilBERT with standard sampling, (2) ViT-B/16 + DistilBERT with balanced sampling, and (3) ViT-L/16 + Bio-ClinicalBERT with balanced sampling. The trained CIPS-Net models (120.60M parameters) were then evaluated in zero-shot and fine-tuned settings on two external datasets: CoNSeP (14 test images, colorectal tissue) and MoNuSAC (85 test images, multi-organ). For comparison, we evaluated SAM (Segment Anything Model, ViT-B, 93.74M parameters) under the same zero-shot and fine-tuned conditions on these external datasets. SAM was fine-tuned for 20 epochs with learning rate $1\times10^{-5}$ on each dataset.

\section{CIPS-Net Training Results on PanNuke (3-Fold CV)}

\begin{table}[h]
\centering
\small
\begin{tabular}{llcccccc}
\toprule
\textbf{Metric} & \textbf{Sampling} & \textbf{Neoplastic} & \textbf{Inflammatory} & \textbf{Connective} & \textbf{Dead} & \textbf{Epithelial} & \textbf{MACRO} \\
\midrule
\multirow{2}{*}{Dice} 
& Standard & 0.960 & 0.589 & 0.402 & 0.356 & 0.614 & 0.584 \\
& Balanced & \textbf{0.963} & \textbf{0.633} & \textbf{0.457} & \textbf{0.380} & \textbf{0.630} & \textbf{0.612} \\
\midrule
\multirow{2}{*}{mPQ} 
& Standard & 0.910 & 0.142 & 0.107 & 0.043 & 0.389 & 0.318 \\
& Balanced & \textbf{0.917} & \textbf{0.217} & \textbf{0.140} & \textbf{0.060} & \textbf{0.431} & \textbf{0.353} \\
\bottomrule
\end{tabular}
\caption{CIPS-Net (ViT-B/16 + DistilBERT) class-wise performance on PanNuke (3-fold CV). Best per class in \textbf{bold}.}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{cipsnet_pannuke_classwise_comparison.png}
\caption{Class-wise Dice and mPQ comparison between Standard and Balanced sampling on PanNuke.}
\end{figure}

\section{CIPS-Net vs SAM on External Datasets}

\begin{table}[h]
\centering
\begin{tabular}{llccc}
\toprule
\textbf{Dataset} & \textbf{Model} & \textbf{Setting} & \textbf{Dice} & \textbf{mPQ} \\
\midrule
\multirow{4}{*}{CoNSeP} 
& CIPS-Net & Zero-Shot & 0.244 & \textcolor{best}{\textbf{0.228}} \\
& SAM & Zero-Shot & \textcolor{best}{\textbf{0.267}} & 0.074 \\
& CIPS-Net & Fine-tuned & \textcolor{best}{\textbf{0.389}} & \textcolor{best}{\textbf{0.143}} \\
& SAM & Fine-tuned & 0.384 & 0.009 \\
\midrule
\multirow{4}{*}{MoNuSAC} 
& CIPS-Net & Zero-Shot & 0.372 & \textcolor{best}{\textbf{0.334}} \\
& SAM & Zero-Shot & \textcolor{best}{\textbf{0.405}} & 0.188 \\
& CIPS-Net & Fine-tuned & \textcolor{best}{\textbf{0.597}} & \textcolor{best}{\textbf{0.357}} \\
& SAM & Fine-tuned & 0.431 & 0.023 \\
\bottomrule
\end{tabular}
\caption{Comparison of CIPS-Net and SAM on external datasets. Best results per setting in \textcolor{best}{green}.}
\end{table}

\section{Conclusion}

CIPS-Net significantly outperforms SAM in instance segmentation quality (mPQ), achieving 3--15$\times$ higher mPQ scores across all experimental settings. While SAM shows slightly better zero-shot binary Dice scores, CIPS-Net demonstrates superior performance after fine-tuning and excels at separating individual nuclei---a critical requirement for computational pathology applications.

\end{document}
